{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.loadtxt('ex5.csv', delimiter=',')\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zmienne wejściowe:\n",
    "Liczba ciąż\n",
    "Stężenie glukozy w osoczu po 2 godzinach w doustnym teście tolerancji glukozy\n",
    "Rozkurczowe ciśnienie krwi (mm Hg)\n",
    "Grubość fałdu skórnego tricepsa (mm)\n",
    "2-godzinne stężenie insuliny w surowicy (μIU/ml)\n",
    "Wskaźnik masy ciała (waga w kg/(wzrost w m)2)\n",
    "Funkcja rodowodu cukrzycy\n",
    "Wiek (lata)\n",
    "\n",
    "Y: Etykieta klasy (0 lub 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier(\n",
      "  (hidden1): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (act1): ReLU()\n",
      "  (hidden2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (act2): ReLU()\n",
      "  (output): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (act_output): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Importuj bibliotekę PyTorch.\n",
    "import torch.nn as nn\n",
    "\n",
    "# Definiuj klasę Classifier, która dziedziczy po nn.Module z PyTorch.\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Definiuj warstwy sieci neuronowej.\n",
    "        # Warstwa ukryta 1 z 8 wejściami i 12 wyjściami.\n",
    "        self.hidden1 = nn.Linear(8, 12)\n",
    "        self.act1 = nn.ReLU()  # Funkcja aktywacji ReLU po warstwie ukrytej 1.\n",
    "        # Warstwa ukryta 2 z 12 wejściami i 8 wyjściami.\n",
    "        self.hidden2 = nn.Linear(12, 8)\n",
    "        self.act2 = nn.ReLU()  # Funkcja aktywacji ReLU po warstwie ukrytej 2.\n",
    "        # Warstwa wyjściowa z 8 wejściami i 1 wyjściem.\n",
    "        self.output = nn.Linear(8, 1)\n",
    "        # Funkcja aktywacji Sigmoid po warstwie wyjściowej.\n",
    "        self.act_output = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Określa przód (forward pass) sieci neuronowej.\n",
    "        # Przeprowadza dane przez warstwę ukrytą 1 z ReLU.\n",
    "        x = self.act1(self.hidden1(x))\n",
    "        # Przeprowadza dane przez warstwę ukrytą 2 z ReLU.\n",
    "        x = self.act2(self.hidden2(x))\n",
    "        # Przeprowadza dane przez warstwę wyjściową z Sigmoid.\n",
    "        x = self.act_output(self.output(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "# Tworzy instancję modelu klasyfikatora.\n",
    "model = Classifier()\n",
    "\n",
    "# Wyświetla definicję modelu.\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoka 0, funkcja straty 0.6671252250671387\n",
      "Epoka 1, funkcja straty 0.6425540447235107\n",
      "Epoka 2, funkcja straty 0.6390970349311829\n",
      "Epoka 3, funkcja straty 0.6318089365959167\n",
      "Epoka 4, funkcja straty 0.6295920014381409\n",
      "Epoka 5, funkcja straty 0.6236585974693298\n",
      "Epoka 6, funkcja straty 0.6226415038108826\n",
      "Epoka 7, funkcja straty 0.6156611442565918\n",
      "Epoka 8, funkcja straty 0.6112000346183777\n",
      "Epoka 9, funkcja straty 0.602994978427887\n",
      "Epoka 10, funkcja straty 0.6101362109184265\n",
      "Epoka 11, funkcja straty 0.5923745036125183\n",
      "Epoka 12, funkcja straty 0.6061577200889587\n",
      "Epoka 13, funkcja straty 0.5833727121353149\n",
      "Epoka 14, funkcja straty 0.5875617265701294\n",
      "Epoka 15, funkcja straty 0.5837463140487671\n",
      "Epoka 16, funkcja straty 0.5793173313140869\n",
      "Epoka 17, funkcja straty 0.5722836256027222\n",
      "Epoka 18, funkcja straty 0.5535190105438232\n",
      "Epoka 19, funkcja straty 0.553154706954956\n",
      "Epoka 20, funkcja straty 0.5466154217720032\n",
      "Epoka 21, funkcja straty 0.5617343187332153\n",
      "Epoka 22, funkcja straty 0.5578280687332153\n",
      "Epoka 23, funkcja straty 0.5387861728668213\n",
      "Epoka 24, funkcja straty 0.5314923524856567\n",
      "Epoka 25, funkcja straty 0.5154544711112976\n",
      "Epoka 26, funkcja straty 0.5051863193511963\n",
      "Epoka 27, funkcja straty 0.5042555928230286\n",
      "Epoka 28, funkcja straty 0.48321059346199036\n",
      "Epoka 29, funkcja straty 0.4690270721912384\n",
      "Epoka 30, funkcja straty 0.4665358364582062\n",
      "Epoka 31, funkcja straty 0.457800030708313\n",
      "Epoka 32, funkcja straty 0.4669992923736572\n",
      "Epoka 33, funkcja straty 0.4469117820262909\n",
      "Epoka 34, funkcja straty 0.4524284601211548\n",
      "Epoka 35, funkcja straty 0.4552314281463623\n",
      "Epoka 36, funkcja straty 0.4506683647632599\n",
      "Epoka 37, funkcja straty 0.4457118809223175\n",
      "Epoka 38, funkcja straty 0.4475720226764679\n",
      "Epoka 39, funkcja straty 0.4456983506679535\n",
      "Epoka 40, funkcja straty 0.4406105577945709\n",
      "Epoka 41, funkcja straty 0.4315573275089264\n",
      "Epoka 42, funkcja straty 0.43077850341796875\n",
      "Epoka 43, funkcja straty 0.442251592874527\n",
      "Epoka 44, funkcja straty 0.42529526352882385\n",
      "Epoka 45, funkcja straty 0.4264773428440094\n",
      "Epoka 46, funkcja straty 0.4250478744506836\n",
      "Epoka 47, funkcja straty 0.42362868785858154\n",
      "Epoka 48, funkcja straty 0.42813771963119507\n",
      "Epoka 49, funkcja straty 0.43395596742630005\n",
      "Epoka 50, funkcja straty 0.43007394671440125\n",
      "Epoka 51, funkcja straty 0.4349585175514221\n",
      "Epoka 52, funkcja straty 0.4253379702568054\n",
      "Epoka 53, funkcja straty 0.43356090784072876\n",
      "Epoka 54, funkcja straty 0.43438437581062317\n",
      "Epoka 55, funkcja straty 0.43474745750427246\n",
      "Epoka 56, funkcja straty 0.43528932332992554\n",
      "Epoka 57, funkcja straty 0.435274213552475\n",
      "Epoka 58, funkcja straty 0.4387646019458771\n",
      "Epoka 59, funkcja straty 0.43268024921417236\n",
      "Epoka 60, funkcja straty 0.42408284544944763\n",
      "Epoka 61, funkcja straty 0.4218705892562866\n",
      "Epoka 62, funkcja straty 0.42924290895462036\n",
      "Epoka 63, funkcja straty 0.42989182472229004\n",
      "Epoka 64, funkcja straty 0.4253358542919159\n",
      "Epoka 65, funkcja straty 0.42955178022384644\n",
      "Epoka 66, funkcja straty 0.41677433252334595\n",
      "Epoka 67, funkcja straty 0.4236554503440857\n",
      "Epoka 68, funkcja straty 0.4312453269958496\n",
      "Epoka 69, funkcja straty 0.4218984544277191\n",
      "Epoka 70, funkcja straty 0.41763144731521606\n",
      "Epoka 71, funkcja straty 0.4259292185306549\n",
      "Epoka 72, funkcja straty 0.4162816107273102\n",
      "Epoka 73, funkcja straty 0.428131639957428\n",
      "Epoka 74, funkcja straty 0.41821685433387756\n",
      "Epoka 75, funkcja straty 0.431160032749176\n",
      "Epoka 76, funkcja straty 0.42603373527526855\n",
      "Epoka 77, funkcja straty 0.4287134110927582\n",
      "Epoka 78, funkcja straty 0.4179624021053314\n",
      "Epoka 79, funkcja straty 0.41898444294929504\n",
      "Epoka 80, funkcja straty 0.4330771267414093\n",
      "Epoka 81, funkcja straty 0.42717400193214417\n",
      "Epoka 82, funkcja straty 0.4242553114891052\n",
      "Epoka 83, funkcja straty 0.42456889152526855\n",
      "Epoka 84, funkcja straty 0.4324316382408142\n",
      "Epoka 85, funkcja straty 0.4247409403324127\n",
      "Epoka 86, funkcja straty 0.4229520559310913\n",
      "Epoka 87, funkcja straty 0.42907392978668213\n",
      "Epoka 88, funkcja straty 0.43426841497421265\n",
      "Epoka 89, funkcja straty 0.42275628447532654\n",
      "Epoka 90, funkcja straty 0.42647886276245117\n",
      "Epoka 91, funkcja straty 0.4311087727546692\n",
      "Epoka 92, funkcja straty 0.4172077178955078\n",
      "Epoka 93, funkcja straty 0.43273016810417175\n",
      "Epoka 94, funkcja straty 0.41886937618255615\n",
      "Epoka 95, funkcja straty 0.43151482939720154\n",
      "Epoka 96, funkcja straty 0.43350112438201904\n",
      "Epoka 97, funkcja straty 0.4309731721878052\n",
      "Epoka 98, funkcja straty 0.4170759916305542\n",
      "Epoka 99, funkcja straty 0.41582977771759033\n"
     ]
    }
   ],
   "source": [
    "# Liczba epok i rozmiar partii (batch size) w treningu.\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "# Pętla treningowa po epokach.\n",
    "for epoch in range(n_epochs):\n",
    "    # Pętla treningowa po danych treningowych z podziałem na partie (mini-batch).\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        # Wybiera partię danych treningowych.\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "\n",
    "        # Przewiduje wyniki za pomocą modelu.\n",
    "        y_pred = model(Xbatch)\n",
    "\n",
    "        # Wybiera odpowiadające etykiety (klasy) dla partii danych.\n",
    "        ybatch = y[i:i+batch_size]\n",
    "\n",
    "        # Oblicza stratę (loss) między przewidywaniami a rzeczywistymi etykietami.\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "\n",
    "        # Wyzerowuje gradienty w optymalizatorze.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Oblicza gradienty straty wstecz (backpropagation).\n",
    "        loss.backward()\n",
    "\n",
    "        # Aktualizuje wagi modelu na podstawie gradientów.\n",
    "        optimizer.step()\n",
    "\n",
    "    # Wyświetla informacje o postępie treningu po każdej epoce.\n",
    "    print(f'Epoka {epoch}, funkcja straty {loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.7473958134651184\n"
     ]
    }
   ],
   "source": [
    "# Ustaw tryb ewaluacji (bez obliczania gradientów) za pomocą torch.no_grad().\n",
    "with torch.no_grad():\n",
    "    # Przewiduje wyniki za pomocą modelu na całym zbiorze danych treningowych.\n",
    "    y_pred = model(X)\n",
    "\n",
    "# Oblicza dokładność (accuracy) modelu na danych treningowych.\n",
    "# Dokładność to procent poprawnie sklasyfikowanych przykładów.\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "\n",
    "# Wyświetla wynik dokładności.\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=8, out_features=12, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=12, out_features=8, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=8, out_features=1, bias=True)\n",
      "  (5): Sigmoid()\n",
      ")\n",
      "Epoka 0, funkcja straty 0.6356704831123352\n",
      "Epoka 1, funkcja straty 0.591513991355896\n",
      "Epoka 2, funkcja straty 0.5675687193870544\n",
      "Epoka 3, funkcja straty 0.553988516330719\n",
      "Epoka 4, funkcja straty 0.5455507040023804\n",
      "Epoka 5, funkcja straty 0.5415869951248169\n",
      "Epoka 6, funkcja straty 0.5392428636550903\n",
      "Epoka 7, funkcja straty 0.5365587472915649\n",
      "Epoka 8, funkcja straty 0.5373504757881165\n",
      "Epoka 9, funkcja straty 0.5395587086677551\n",
      "Epoka 10, funkcja straty 0.5424097180366516\n",
      "Epoka 11, funkcja straty 0.5407059788703918\n",
      "Epoka 12, funkcja straty 0.5418652296066284\n",
      "Epoka 13, funkcja straty 0.5394490361213684\n",
      "Epoka 14, funkcja straty 0.541008710861206\n",
      "Epoka 15, funkcja straty 0.5395030379295349\n",
      "Epoka 16, funkcja straty 0.5443186163902283\n",
      "Epoka 17, funkcja straty 0.5401498079299927\n",
      "Epoka 18, funkcja straty 0.5414392948150635\n",
      "Epoka 19, funkcja straty 0.5400640368461609\n",
      "Epoka 20, funkcja straty 0.5470967888832092\n",
      "Epoka 21, funkcja straty 0.5389971733093262\n",
      "Epoka 22, funkcja straty 0.5330811142921448\n",
      "Epoka 23, funkcja straty 0.533431351184845\n",
      "Epoka 24, funkcja straty 0.5253969430923462\n",
      "Epoka 25, funkcja straty 0.5259829759597778\n",
      "Epoka 26, funkcja straty 0.5200363993644714\n",
      "Epoka 27, funkcja straty 0.5216288566589355\n",
      "Epoka 28, funkcja straty 0.5153588652610779\n",
      "Epoka 29, funkcja straty 0.5133318305015564\n",
      "Epoka 30, funkcja straty 0.5187615156173706\n",
      "Epoka 31, funkcja straty 0.5191036462783813\n",
      "Epoka 32, funkcja straty 0.5124102830886841\n",
      "Epoka 33, funkcja straty 0.4995395243167877\n",
      "Epoka 34, funkcja straty 0.5051648020744324\n",
      "Epoka 35, funkcja straty 0.5023090243339539\n",
      "Epoka 36, funkcja straty 0.5135720372200012\n",
      "Epoka 37, funkcja straty 0.49288058280944824\n",
      "Epoka 38, funkcja straty 0.4942719340324402\n",
      "Epoka 39, funkcja straty 0.49150708317756653\n",
      "Epoka 40, funkcja straty 0.5070037841796875\n",
      "Epoka 41, funkcja straty 0.48515698313713074\n",
      "Epoka 42, funkcja straty 0.485806941986084\n",
      "Epoka 43, funkcja straty 0.48019909858703613\n",
      "Epoka 44, funkcja straty 0.47787341475486755\n",
      "Epoka 45, funkcja straty 0.49870702624320984\n",
      "Epoka 46, funkcja straty 0.4852331876754761\n",
      "Epoka 47, funkcja straty 0.48486512899398804\n",
      "Epoka 48, funkcja straty 0.48617738485336304\n",
      "Epoka 49, funkcja straty 0.4932069182395935\n",
      "Epoka 50, funkcja straty 0.4828806519508362\n",
      "Epoka 51, funkcja straty 0.4817141890525818\n",
      "Epoka 52, funkcja straty 0.47061988711357117\n",
      "Epoka 53, funkcja straty 0.4733036458492279\n",
      "Epoka 54, funkcja straty 0.4636901915073395\n",
      "Epoka 55, funkcja straty 0.4588909447193146\n",
      "Epoka 56, funkcja straty 0.477953165769577\n",
      "Epoka 57, funkcja straty 0.4710901975631714\n",
      "Epoka 58, funkcja straty 0.4566729664802551\n",
      "Epoka 59, funkcja straty 0.46760907769203186\n",
      "Epoka 60, funkcja straty 0.46117016673088074\n",
      "Epoka 61, funkcja straty 0.43302133679389954\n",
      "Epoka 62, funkcja straty 0.44396623969078064\n",
      "Epoka 63, funkcja straty 0.44265323877334595\n",
      "Epoka 64, funkcja straty 0.43483251333236694\n",
      "Epoka 65, funkcja straty 0.4533064067363739\n",
      "Epoka 66, funkcja straty 0.43901005387306213\n",
      "Epoka 67, funkcja straty 0.41350290179252625\n",
      "Epoka 68, funkcja straty 0.4370076656341553\n",
      "Epoka 69, funkcja straty 0.428622305393219\n",
      "Epoka 70, funkcja straty 0.425229012966156\n",
      "Epoka 71, funkcja straty 0.435638964176178\n",
      "Epoka 72, funkcja straty 0.43071815371513367\n",
      "Epoka 73, funkcja straty 0.4239932894706726\n",
      "Epoka 74, funkcja straty 0.4217703342437744\n",
      "Epoka 75, funkcja straty 0.413913756608963\n",
      "Epoka 76, funkcja straty 0.41825225949287415\n",
      "Epoka 77, funkcja straty 0.4294981062412262\n",
      "Epoka 78, funkcja straty 0.4046226739883423\n",
      "Epoka 79, funkcja straty 0.3719615638256073\n",
      "Epoka 80, funkcja straty 0.4124546945095062\n",
      "Epoka 81, funkcja straty 0.400717169046402\n",
      "Epoka 82, funkcja straty 0.4013076424598694\n",
      "Epoka 83, funkcja straty 0.41556164622306824\n",
      "Epoka 84, funkcja straty 0.3943333923816681\n",
      "Epoka 85, funkcja straty 0.39188650250434875\n",
      "Epoka 86, funkcja straty 0.40636664628982544\n",
      "Epoka 87, funkcja straty 0.3945603668689728\n",
      "Epoka 88, funkcja straty 0.38937005400657654\n",
      "Epoka 89, funkcja straty 0.3840045928955078\n",
      "Epoka 90, funkcja straty 0.3838377594947815\n",
      "Epoka 91, funkcja straty 0.3744601905345917\n",
      "Epoka 92, funkcja straty 0.3774875998497009\n",
      "Epoka 93, funkcja straty 0.37485334277153015\n",
      "Epoka 94, funkcja straty 0.3843192458152771\n",
      "Epoka 95, funkcja straty 0.375735342502594\n",
      "Epoka 96, funkcja straty 0.37196698784828186\n",
      "Epoka 97, funkcja straty 0.36946091055870056\n",
      "Epoka 98, funkcja straty 0.36486250162124634\n",
      "Epoka 99, funkcja straty 0.3744000494480133\n",
      "Accuracy 0.7578125\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "dataset = np.loadtxt('ex5.csv', delimiter=',')\n",
    "X = dataset[:, 0:8]\n",
    "y = dataset[:, 8]\n",
    "\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(8, 12),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(12, 8),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(8, 1),\n",
    "    nn.Sigmoid()\n",
    ")\n",
    "print(model)\n",
    "\n",
    "\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        Xbatch = X[i:i+batch_size]\n",
    "        y_pred = model(Xbatch)\n",
    "        ybatch = y[i:i+batch_size]\n",
    "        loss = loss_fn(y_pred, ybatch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoka {epoch}, funkcja straty {loss}')\n",
    "\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X)\n",
    "accuracy = (y_pred.round() == y).float().mean()\n",
    "print(f\"Accuracy {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model(X)\n",
    "\n",
    "rounded = predictions.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = (model(X) > 0.5).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.599998474121094, 0.6269999742507935, 50.0] => 1 (oczekiwane 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.600000381469727, 0.35100001096725464, 31.0] => 0 (oczekiwane 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.299999237060547, 0.671999990940094, 32.0] => 1 (oczekiwane 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.100000381469727, 0.16699999570846558, 21.0] => 0 (oczekiwane 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.099998474121094, 2.2880001068115234, 33.0] => 1 (oczekiwane 1)\n",
      "[5.0, 116.0, 74.0, 0.0, 0.0, 25.600000381469727, 0.20100000500679016, 30.0] => 0 (oczekiwane 0)\n",
      "[3.0, 78.0, 50.0, 32.0, 88.0, 31.0, 0.24799999594688416, 26.0] => 0 (oczekiwane 1)\n",
      "[10.0, 115.0, 0.0, 0.0, 0.0, 35.29999923706055, 0.1340000033378601, 29.0] => 1 (oczekiwane 0)\n",
      "[2.0, 197.0, 70.0, 45.0, 543.0, 30.5, 0.15800000727176666, 53.0] => 1 (oczekiwane 1)\n",
      "[8.0, 125.0, 96.0, 0.0, 0.0, 0.0, 0.23199999332427979, 54.0] => 0 (oczekiwane 1)\n"
     ]
    }
   ],
   "source": [
    "predictions = (model(X) > 0.5).int()\n",
    "for i in range(10):\n",
    "    print('%s => %d (oczekiwane %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
